{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bAbi data_loader\n",
    "Original code : https://github.com/YerevaNN/Dynamic-memory-networks-in-Theano/blob/master/utils.py\n",
    "\"\"\"\n",
    "\n",
    "import os as os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    def __init__(self, task_id, task_test_id, w2v_dim=100, input_mask_mode=\"sentence\", use_pretrained=True):\n",
    "        self.base_path = os.path.join(\"data/\")\n",
    "\n",
    "        self.task_id = str(task_id)\n",
    "        self.task_test_id = str(task_test_id)\n",
    "        self.w2v_dim = w2v_dim\n",
    "        self.input_mask_mode = input_mask_mode\n",
    "        self.use_pretrained = use_pretrained\n",
    "\n",
    "    def make_train_and_test_set(self):\n",
    "        train_raw, test_raw = self.get_babi_raw(self.task_id, self.task_test_id)\n",
    "        self.max_facts_seq_len, self.max_question_seq_len, self.max_input_mask_len = self.get_max_seq_length(train_raw, test_raw)\n",
    "        \n",
    "        if self.use_pretrained:\n",
    "            self.word2vec = self.load_glove(self.w2v_dim)\n",
    "        else:\n",
    "            self.word2vec = {}\n",
    "        self.vocab = {}\n",
    "        self.ivocab = {}\n",
    "        \n",
    "        self.create_vector(\"unknown\")\n",
    "\n",
    "        train_input, train_question, train_answer, train_input_mask = self.process_input(train_raw)\n",
    "        test_input, test_question, test_answer, test_input_mask = self.process_input(test_raw)\n",
    "\n",
    "        return {\n",
    "            \"train\": (train_input, train_input_mask, train_question, train_answer),\n",
    "            \"test\": (test_input, test_input_mask, test_question, test_answer)\n",
    "        }\n",
    "    \n",
    "    def get_max_seq_length(self, *datasets):\n",
    "        max_facts_length, max_question_length, max_input_mask_length = 0, 0, 0\n",
    "        \n",
    "        def count_punctuation(facts):\n",
    "            return len(list(filter(lambda x: x == \".\", facts)))\n",
    "        \n",
    "        for dataset in datasets:\n",
    "            for d in dataset:\n",
    "                max_facts_length = max(max_facts_length, len(d['C'].split()))\n",
    "                max_input_mask_length = max(max_input_mask_length, count_punctuation(d['C']))\n",
    "                max_question_length = max(max_question_length, len(d['Q'].split()))\n",
    "        return max_facts_length, max_question_length, max_input_mask_length\n",
    "\n",
    "    def init_babi(self, fname):\n",
    "        print(\"==> Loading test from %s\" % fname)\n",
    "        tasks = []\n",
    "        task = None\n",
    "        for i, line in enumerate(open(fname)):\n",
    "            id = int(line[0:line.find(' ')])\n",
    "            if id == 1:\n",
    "                task = {\"C\": \"\", \"Q\": \"\", \"A\": \"\"}\n",
    "\n",
    "            line = line.strip()\n",
    "            line = line.replace('.', ' . ')\n",
    "            line = line[line.find(' ')+1:]\n",
    "            if line.find('?') == -1:\n",
    "                task[\"C\"] += line\n",
    "            else:\n",
    "                idx = line.find('?')\n",
    "                tmp = line[idx+1:].split('\\t')\n",
    "                task[\"Q\"] = line[:idx]\n",
    "                task[\"A\"] = tmp[1].strip()\n",
    "                tasks.append(task.copy())\n",
    "\n",
    "        return tasks\n",
    "\n",
    "\n",
    "    def get_babi_raw(self, id, test_id):\n",
    "        babi_map = {\n",
    "            \"1\": \"qa1_single-supporting-fact\",\n",
    "            \"2\": \"qa2_two-supporting-facts\",\n",
    "            \"3\": \"qa3_three-supporting-facts\",\n",
    "            \"4\": \"qa4_two-arg-relations\",\n",
    "            \"5\": \"qa5_three-arg-relations\",\n",
    "            \"6\": \"qa6_yes-no-questions\",\n",
    "            \"7\": \"qa7_counting\",\n",
    "            \"8\": \"qa8_lists-sets\",\n",
    "            \"9\": \"qa9_simple-negation\",\n",
    "            \"10\": \"qa10_indefinite-knowledge\",\n",
    "            \"11\": \"qa11_basic-coreference\",\n",
    "            \"12\": \"qa12_conjunction\",\n",
    "            \"13\": \"qa13_compound-coreference\",\n",
    "            \"14\": \"qa14_time-reasoning\",\n",
    "            \"15\": \"qa15_basic-deduction\",\n",
    "            \"16\": \"qa16_basic-induction\",\n",
    "            \"17\": \"qa17_positional-reasoning\",\n",
    "            \"18\": \"qa18_size-reasoning\",\n",
    "            \"19\": \"qa19_path-finding\",\n",
    "            \"20\": \"qa20_agents-motivations\",\n",
    "            \"MCTest\": \"MCTest\",\n",
    "            \"19changed\": \"19changed\",\n",
    "            \"joint\": \"all_shuffled\",\n",
    "            \"sh1\": \"../shuffled/qa1_single-supporting-fact\",\n",
    "            \"sh2\": \"../shuffled/qa2_two-supporting-facts\",\n",
    "            \"sh3\": \"../shuffled/qa3_three-supporting-facts\",\n",
    "            \"sh4\": \"../shuffled/qa4_two-arg-relations\",\n",
    "            \"sh5\": \"../shuffled/qa5_three-arg-relations\",\n",
    "            \"sh6\": \"../shuffled/qa6_yes-no-questions\",\n",
    "            \"sh7\": \"../shuffled/qa7_counting\",\n",
    "            \"sh8\": \"../shuffled/qa8_lists-sets\",\n",
    "            \"sh9\": \"../shuffled/qa9_simple-negation\",\n",
    "            \"sh10\": \"../shuffled/qa10_indefinite-knowledge\",\n",
    "            \"sh11\": \"../shuffled/qa11_basic-coreference\",\n",
    "            \"sh12\": \"../shuffled/qa12_conjunction\",\n",
    "            \"sh13\": \"../shuffled/qa13_compound-coreference\",\n",
    "            \"sh14\": \"../shuffled/qa14_time-reasoning\",\n",
    "            \"sh15\": \"../shuffled/qa15_basic-deduction\",\n",
    "            \"sh16\": \"../shuffled/qa16_basic-induction\",\n",
    "            \"sh17\": \"../shuffled/qa17_positional-reasoning\",\n",
    "            \"sh18\": \"../shuffled/qa18_size-reasoning\",\n",
    "            \"sh19\": \"../shuffled/qa19_path-finding\",\n",
    "            \"sh20\": \"../shuffled/qa20_agents-motivations\",\n",
    "        }\n",
    "        if (test_id == \"\"):\n",
    "            test_id = id\n",
    "        babi_name = babi_map[id]\n",
    "        babi_test_name = babi_map[test_id]\n",
    "        babi_train_raw = self.init_babi(os.path.join(self.base_path, 'en-10/%s_train.txt' % babi_name))\n",
    "        babi_test_raw = self.init_babi(os.path.join(self.base_path, 'en-10/%s_test.txt' % babi_test_name))\n",
    "        return babi_train_raw, babi_test_raw\n",
    "\n",
    "    def load_glove(self, dim):\n",
    "        word2vec = {}\n",
    "\n",
    "        print(\"==> loading glove\")\n",
    "        with open(os.path.join(self.base_path, \"glove/glove.6B.\" + str(dim) + \"d.txt\")) as f:\n",
    "            for line in tqdm(f):\n",
    "                l = line.split()\n",
    "                word2vec[l[0]] = l[1:]\n",
    "\n",
    "        print(\"==> glove is loaded\")\n",
    "\n",
    "        return word2vec\n",
    "\n",
    "    def create_vector(self, word, silent=False):\n",
    "        # if the word is missing from Glove, create some fake vector and store in glove!\n",
    "        vector = np.random.uniform(0.0, 1.0, (self.w2v_dim,))\n",
    "        self.word2vec[word] = vector\n",
    "        if (not silent):\n",
    "            print(\"data_loader.py::create_vector => %s is missing\" % word)\n",
    "        return vector\n",
    "\n",
    "    def process_word(self, word, to_return=\"word2vec\", silent=False):\n",
    "        if not word in self.word2vec:\n",
    "            self.create_vector(word, silent=silent)\n",
    "        if not word in self.vocab:\n",
    "            next_index = len(self.vocab)\n",
    "            self.vocab[word] = next_index\n",
    "            self.ivocab[next_index] = word\n",
    "\n",
    "        if to_return == \"word2vec\":\n",
    "            return self.word2vec[word]\n",
    "        elif to_return == \"index\":\n",
    "            return self.vocab[word]\n",
    "        else:\n",
    "            raise ValueError(\"return type is 'word2vec' or 'index'\")\n",
    "\n",
    "    def get_norm(self, x):\n",
    "        x = np.array(x)\n",
    "        return np.sum(x * x)\n",
    "\n",
    "    def process_input(self, data_raw):\n",
    "        questions = []\n",
    "        inputs = []\n",
    "        answers = []\n",
    "        input_masks = []\n",
    "        \n",
    "        for x in data_raw:\n",
    "            inp = x[\"C\"].lower().split(' ')\n",
    "            inp = [w for w in inp if len(w) > 0]\n",
    "            \n",
    "            q = x[\"Q\"].lower().split(' ')\n",
    "            q = [w for w in q if len(w) > 0]\n",
    "\n",
    "            inp_vector = [self.process_word(word=w, to_return=\"word2vec\") for w in inp]\n",
    "            inp_vector = self.pad_input(inp_vector, self.max_facts_seq_len, [np.zeros(self.w2v_dim)])\n",
    "            \n",
    "            q_vector = [self.process_word(word=w, to_return=\"word2vec\") for w in q]\n",
    "            q_vector = self.pad_input(q_vector, self.max_question_seq_len, [np.zeros(self.w2v_dim)])\n",
    "            \n",
    "            inputs.append(np.vstack(inp_vector).astype(float))            \n",
    "            questions.append(np.vstack(q_vector).astype(float))\n",
    "            answers.append(self.process_word(word = x[\"A\"], to_return = \"index\"))\n",
    "\n",
    "            if self.input_mask_mode == 'word':\n",
    "                input_masks.append(np.array([index for index, w in enumerate(inp)], dtype=np.int32))\n",
    "            elif self.input_mask_mode == 'sentence':\n",
    "                input_mask = [index for index, w in enumerate(inp) if w == '.']\n",
    "                input_mask = self.pad_input(input_mask, self.max_input_mask_len, [0])\n",
    "                input_masks.append(input_mask)\n",
    "            else:\n",
    "                raise ValueError(\"input_mask_mode is only available (word, sentence)\")\n",
    "            \n",
    "        return (np.array(inputs, dtype=np.float32), \n",
    "                np.array(questions, dtype=np.float32),\n",
    "                np.array(answers, dtype=np.int32).reshape(-1, 1), \n",
    "                np.array(input_masks, dtype=np.int32))\n",
    "    \n",
    "    def pad_input(self, input_, size, pad_item):\n",
    "        return input_ + pad_item * (size - len(input_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading test from data/en-10/qa1_single-supporting-fact_train.txt\n",
      "==> Loading test from data/en-10/qa1_single-supporting-fact_test.txt\n",
      "data_loader.py::create_vector => unknown is missing\n",
      "data_loader.py::create_vector => mary is missing\n",
      "data_loader.py::create_vector => moved is missing\n",
      "data_loader.py::create_vector => to is missing\n",
      "data_loader.py::create_vector => the is missing\n",
      "data_loader.py::create_vector => bathroom is missing\n",
      "data_loader.py::create_vector => . is missing\n",
      "data_loader.py::create_vector => john is missing\n",
      "data_loader.py::create_vector => went is missing\n",
      "data_loader.py::create_vector => hallway is missing\n",
      "data_loader.py::create_vector => where is missing\n",
      "data_loader.py::create_vector => is is missing\n",
      "data_loader.py::create_vector => daniel is missing\n",
      "data_loader.py::create_vector => back is missing\n",
      "data_loader.py::create_vector => sandra is missing\n",
      "data_loader.py::create_vector => garden is missing\n",
      "data_loader.py::create_vector => office is missing\n",
      "data_loader.py::create_vector => journeyed is missing\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader(task_id=\"1\", task_test_id=\"1\", w2v_dim=50, use_pretrained=False)\n",
    "data = data_loader.make_train_and_test_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Loading test from data/en-10/qa1_single-supporting-fact_train.txt\n",
      "==> Loading test from data/en-10/qa1_single-supporting-fact_test.txt\n"
     ]
    }
   ],
   "source": [
    "train_raw, test_raw = data_loader.get_babi_raw(\"1\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'A': 'bathroom',\n",
       "  'C': 'Mary moved to the bathroom . John went to the hallway . ',\n",
       "  'Q': 'Where is Mary'},\n",
       " {'A': 'hallway',\n",
       "  'C': 'Mary moved to the bathroom . John went to the hallway . Daniel went back to the hallway . Sandra moved to the garden . ',\n",
       "  'Q': 'Where is Daniel'},\n",
       " {'A': 'hallway',\n",
       "  'C': 'Mary moved to the bathroom . John went to the hallway . Daniel went back to the hallway . Sandra moved to the garden . John moved to the office . Sandra journeyed to the bathroom . ',\n",
       "  'Q': 'Where is Daniel'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 37, 50) (3, 6) (3, 3, 50) (3, 1)\n"
     ]
    }
   ],
   "source": [
    "train_input, train_input_mask, train_question, train_answer = data[\"train\"]\n",
    "print(train_input.shape, train_input_mask.shape, train_question.shape, train_answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 37, 50)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 50)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 11,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_question[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_answer[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.max_facts_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader.max_question_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (NLP)",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
